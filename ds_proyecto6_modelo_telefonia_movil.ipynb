{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Machine Learning para la empresa de telefonía móvil Megaline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de Contenidos<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introducción\" data-toc-modified-id=\"Introducción-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introducción</a></span></li><li><span><a href=\"#Objetivos\" data-toc-modified-id=\"Objetivos-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Objetivos</a></span></li><li><span><a href=\"#Inicialización\" data-toc-modified-id=\"Inicialización-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Inicialización</a></span><ul class=\"toc-item\"><li><span><a href=\"#Cargar-datos\" data-toc-modified-id=\"Cargar-datos-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Cargar datos</a></span></li><li><span><a href=\"#Explorar-datos-iniciales\" data-toc-modified-id=\"Explorar-datos-iniciales-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Explorar datos iniciales</a></span></li><li><span><a href=\"#Conclusiones\" data-toc-modified-id=\"Conclusiones-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Conclusiones</a></span></li></ul></li><li><span><a href=\"#Segmentación-de-datos-fuente\" data-toc-modified-id=\"Segmentación-de-datos-fuente-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Segmentación de datos fuente</a></span><ul class=\"toc-item\"><li><span><a href=\"#Conclusiones\" data-toc-modified-id=\"Conclusiones-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Conclusiones</a></span></li></ul></li><li><span><a href=\"#Investigación-de-modelos-predictivos\" data-toc-modified-id=\"Investigación-de-modelos-predictivos-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Investigación de modelos predictivos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Árbol-de-decisión\" data-toc-modified-id=\"Árbol-de-decisión-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Árbol de decisión</a></span></li><li><span><a href=\"#Bosque-Aleatorio\" data-toc-modified-id=\"Bosque-Aleatorio-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Bosque Aleatorio</a></span></li><li><span><a href=\"#Regresión-Logística\" data-toc-modified-id=\"Regresión-Logística-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Regresión Logística</a></span></li></ul></li><li><span><a href=\"#Calidad-del-modelo\" data-toc-modified-id=\"Calidad-del-modelo-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Calidad del modelo</a></span></li><li><span><a href=\"#Prueba-de-cordura\" data-toc-modified-id=\"Prueba-de-cordura-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Prueba de cordura</a></span></li><li><span><a href=\"#Conclusiones\" data-toc-modified-id=\"Conclusiones-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Conclusiones</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "\n",
    "La compañía móvil Megaline no está satisfecha al ver que muchos de sus clientes utilizan planes heredados. La mayor parte de usuarios utilizan planes ilimitados antiguos, siendo pocos los que han actualizado su plan a uno más nuevo. Un plan más moderno presenta varios beneficios desde funciones adicionales hasta precios más bajos. Considerando todo esto, la compañía busca desarrollar un modelo que pueda analizar el comportamiento de los clientes y recomendar uno de los nuevos planes de Megaline: Smart o Ultimate.\n",
    "\n",
    "Para lograr esto, se utilizará machine learning, una herramienta que permite crear modelos predictivos a partir de un conjunto de datos, mientras más datos más complejos pueden ser los programas que se pueden escribir. En este proyecto se tiene acceso a los datos de comportamiento de los suscriptores que ya se han cambiado a los planes nuevos, y lo que buscaremos es crear un modelo predictivo que escoja el plan correcto con un umbral de exactitud de 0.75. \n",
    "\n",
    "## Objetivos\n",
    "\n",
    "1. Establecer el mejor modelo predictivo que permita escoger el plan de telefonía correcto para clientes con planes heredados. \n",
    "2. Investigar la calidad de diferentes modelos predictivos y escoger aquel modelo con la exactitud más alta. \n",
    "3. Comprobar la calidad del modelo.\n",
    "4. Realizar una prueba de cordura al modelo. \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialización\n",
    "\n",
    "En primer lugar, vamos a importar todas las librerías necesarias que permitan un correcto desarrollo de un modelo de machen learning. En este caso trabajaremos con la librería `pandas` y Scikit-learn o `sklearn` que nos permitirán leer los archivos, trabajar con datos y crear modelos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar datos\n",
    "\n",
    "En segundo lugar, vamos a importar el archivo con la información de planes de telefonía, para esto llamaremos a la función `pd.read_csv` de la librería pandas y colocaremos como argumento la dirección en la cual se encuentra nuestro dataset, el cual será guardado en la variable `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explorar datos iniciales\n",
    "\n",
    "Una vez importado el dataset con la información sobre planes de servicios móviles, vamos a examinar la información con la que se trabajará en nuestro modelo de machine learning. Para esto llamamos al atributo `shape`, y a los métodos `head` y `tail`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3214, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3209</th>\n",
       "      <td>122.0</td>\n",
       "      <td>910.98</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35124.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3210</th>\n",
       "      <td>25.0</td>\n",
       "      <td>190.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3275.61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3211</th>\n",
       "      <td>97.0</td>\n",
       "      <td>634.44</td>\n",
       "      <td>70.0</td>\n",
       "      <td>13974.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3212</th>\n",
       "      <td>64.0</td>\n",
       "      <td>462.32</td>\n",
       "      <td>90.0</td>\n",
       "      <td>31239.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3213</th>\n",
       "      <td>80.0</td>\n",
       "      <td>566.09</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29480.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      calls  minutes  messages   mb_used  is_ultra\n",
       "3209  122.0   910.98      20.0  35124.90         1\n",
       "3210   25.0   190.36       0.0   3275.61         0\n",
       "3211   97.0   634.44      70.0  13974.06         0\n",
       "3212   64.0   462.32      90.0  31239.78         0\n",
       "3213   80.0   566.09       6.0  29480.52         1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro dataset `df` cuenta con 3214 observaciones, cada observación contiene información sobre el comportamiento mensual sobre un usuario. La información dada es la siguiente:\n",
    "\n",
    "- `calls`: número de llamadas,\n",
    "- `minutes`: duración total de la llamada en minutos,\n",
    "- `messages`: número de mensajes de texto,\n",
    "- `mb_used`: tráfico de Internet utilizado en MB,\n",
    "- `is_ultra`: plan para el mes actual (Ultimate - 1, Surf - 0)\n",
    "\n",
    "Podemos observar que las características/variables de nuestros datos corresponden a `calls`, `minutes`, `messages` y `mb_used`. Las preguntas para el desarrollo de nuestro modelo se desarrollarán en base a estas cuatro características. Mientras que las columna `is_ultra` es nuestro característica a predecir u objetivo.  \n",
    "\n",
    "Ahora comprobaremos que no existan valores duplicados o ausentes, llamando al método `info`, `isna` y `duplicated`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calls       0\n",
       "minutes     0\n",
       "messages    0\n",
       "mb_used     0\n",
       "is_ultra    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al llamar al método info  e isna en todo nuestro dataset se confirma que no existen valores ausentes, encontrando el mismo número de filas en todas las columnas. A su vez se confirma que los tipos de datos son los correctos para todas las variables que van a ser estudiadas. Al llamar al método duplicated y sum no se registran valores duplicados en nuestro dataset.\n",
    "\n",
    "Ahora analizaremos los datos categóricos del dataset, para esto aplicaremos value_counts a la columna `is_ultra`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2229\n",
       "1     985\n",
       "Name: is_ultra, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_ultra'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se registran más clientes pertenecientes al plan Surf con 2229 registros, mientras que para el plan Ultimate se observan 985 registros. Finalmente, analicemos las variables numéricas en nuestro dataset, para esto aplicaremos el método describe() a las columnas `calls`, `minutes`, `messages` y `mb_used`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "      <td>3214.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>63.038892</td>\n",
       "      <td>438.208787</td>\n",
       "      <td>38.281269</td>\n",
       "      <td>17207.673836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>33.236368</td>\n",
       "      <td>234.569872</td>\n",
       "      <td>36.148326</td>\n",
       "      <td>7570.968246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>274.575000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12491.902500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>430.600000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>16943.235000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>571.927500</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>21424.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>244.000000</td>\n",
       "      <td>1632.060000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>49745.730000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             calls      minutes     messages       mb_used\n",
       "count  3214.000000  3214.000000  3214.000000   3214.000000\n",
       "mean     63.038892   438.208787    38.281269  17207.673836\n",
       "std      33.236368   234.569872    36.148326   7570.968246\n",
       "min       0.000000     0.000000     0.000000      0.000000\n",
       "25%      40.000000   274.575000     9.000000  12491.902500\n",
       "50%      62.000000   430.600000    30.000000  16943.235000\n",
       "75%      82.000000   571.927500    57.000000  21424.700000\n",
       "max     244.000000  1632.060000   224.000000  49745.730000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_df = df[['calls', 'minutes', 'messages', 'mb_used']]\n",
    "numerical_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto para la columna `calls`, `minutes`, `messages` y `mb_used` se registra un promedio mayor a la mediana, por lo que se puede establecer una asimetría positiva, con un mayor número de valores a la derecha del pico más alto, lo que denota un sesgo hacia la derecha de nuestros datos. A su vez, se registran altas desviaciones estándar, por lo que se puede confirmar la presencia de valores atípicos, esto también se evidencia en los valores máximos de las cuatro variables, que representan más de tres desviaciones estándar. \n",
    "\n",
    "### Conclusiones\n",
    "\n",
    "1. Nuestro dataset no presentó valores ausentes ni tampoco valores duplicados, y a su vez no se evidenciaron tipos de datos incorrectos que requieran una posterior correción.\n",
    "2. Para construir nuestro modelo de machine leargning se necesitará trabajar con las columnas `calls`, `minutes`, `messages` y `mb_used` como características, mientras que la columna `is_ultra` será nuestro variable objetivo. \n",
    "3. Al analizar las variables categóricas se observa un mayor número de registros en el Plan Surf, en comparación con el Plan Ultimate. Por otro lado, al analizar las variables numéricas se observó que todas las variables presentan una asimetría positiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentación de datos fuente\n",
    "\n",
    "Como se mencionó anteriormente las características de nuestro modelo serán `calls`, `minutes`, `messages` y `mb_used`, mientras que el objetivo será el tipo de plan `is_ultra`. En este caso desarrollaremos un modelo predictivo de aprendizaje supervisado, ya que tratamos de reproducir un valor conocido de un conjunto de datos. El tipo de tarea con la que se trabajará es una tarea de clasificación binaria con un objetivo categórico que presenta dos posibles respuestas Ultimate-1 o Surf-0.\n",
    "\n",
    "Una vez definidas las observaciones, características, objetivo y tipo de tarea de nuestro dataset fuente, vamos a proceder con su segmentación. En este caso, será necesario dividir nuestros datos en tres datasets: dataset de entrenamiento, dataset de validación y dataset prueba. Se realizará esta división ya que no contamos con un dataset de prueba y un dataset de validación mostrará como se comporta el modelo y si existe un sobreajuste. \n",
    "\n",
    "Al dividir un dataset fuente en tres partes la proporción ideal es de 3:1:1, es decir el 60% de datos se asignarán al conjunto de entrenamiento, 20% al conjunto de validación y 20% al conjunto de prueba. Para realizar la división utilizaremos la función `train_test_split` de la librería Skicit-Learn. \n",
    "\n",
    "Empezaremos dividiendo nuestro dataset fuente `df` en el conjunto de datos para el entrenamiento `df_train` con el 60% de datos, y `df_40` que contendrá el 40% de los datos, para esto estableceremos los parámetros `test_size` en 0.40 y `random_state` en 12345. Posteriormente, vamos a dividir `df_40` en nuestros conjuntos de validación `df_valid` y de prueba `df_test`. Cada conjunto contiene el 20% de los datos, por lo que estableceremos `test_size` en 0.50, para obtener dos datasets que contengas el 50% del dataset `df_40` que a su vez correspondría con el 20% del dataset fuente.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_40 = train_test_split(df, test_size=0.40, random_state=12345)\n",
    "\n",
    "df_valid, df_test = train_test_split(df_40, test_size=0.50, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que nuestros conjunto de datos de entrenamiento `df_train`, validación `df_valid` y prueba `df_test` se hayan dividido correctamente llamando al método info en cada dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1928 entries, 3027 to 482\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     1928 non-null   float64\n",
      " 1   minutes   1928 non-null   float64\n",
      " 2   messages  1928 non-null   float64\n",
      " 3   mb_used   1928 non-null   float64\n",
      " 4   is_ultra  1928 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 90.4 KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 643 entries, 1386 to 3197\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     643 non-null    float64\n",
      " 1   minutes   643 non-null    float64\n",
      " 2   messages  643 non-null    float64\n",
      " 3   mb_used   643 non-null    float64\n",
      " 4   is_ultra  643 non-null    int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 30.1 KB\n"
     ]
    }
   ],
   "source": [
    "df_valid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 643 entries, 160 to 2313\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     643 non-null    float64\n",
      " 1   minutes   643 non-null    float64\n",
      " 2   messages  643 non-null    float64\n",
      " 3   mb_used   643 non-null    float64\n",
      " 4   is_ultra  643 non-null    int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 30.1 KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se verifica entonces que el dataset de entrenamiento contiene el 60% de datos(1928 observaciones), y los dataset de validación y prueba el 20% de datos(643 observaciones cada uno). \n",
    "\n",
    "Una vez establecidos nuestros tres conjuntos de datos, vamos a establecer las características y objetivos de cada dataset. Para las características vamos a utilizar la función drop que eliminará la columna `is_ultra`, y nos quedaremos únicamente con las columnas `calls`, `minutes`, `messages` y `mb_used`, guardaremos estos resultados en las variables `features_train`, `features_valid` y `features_test`. Para el objetivo de cada dataset simplemente llamaremos a la columna `is_ultra` y se guardarán estos valores en las variables `target_train`, `target_valid` y `target_test`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establecemos las características y objetivo del conjunto de datos para el entrenamiento\n",
    "features_train = df_train.drop('is_ultra', axis=1)\n",
    "target_train = df_train['is_ultra']\n",
    "\n",
    "# Establecemos las características y objetivo del conjunto de datos para la validación\n",
    "features_valid = df_valid.drop('is_ultra', axis=1)\n",
    "target_valid = df_valid['is_ultra']\n",
    "\n",
    "# Establecemos las características y objetivo del conjunto de datos para la prueba\n",
    "features_test = df_test.drop('is_ultra', axis=1)\n",
    "target_test = df_test['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos que los nuevos datasets solo presenten las características llamando al método info en cada conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1928 entries, 3027 to 482\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     1928 non-null   float64\n",
      " 1   minutes   1928 non-null   float64\n",
      " 2   messages  1928 non-null   float64\n",
      " 3   mb_used   1928 non-null   float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 75.3 KB\n"
     ]
    }
   ],
   "source": [
    "features_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 643 entries, 1386 to 3197\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     643 non-null    float64\n",
      " 1   minutes   643 non-null    float64\n",
      " 2   messages  643 non-null    float64\n",
      " 3   mb_used   643 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 25.1 KB\n"
     ]
    }
   ],
   "source": [
    "features_valid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 643 entries, 160 to 2313\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     643 non-null    float64\n",
      " 1   minutes   643 non-null    float64\n",
      " 2   messages  643 non-null    float64\n",
      " 3   mb_used   643 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 25.1 KB\n"
     ]
    }
   ],
   "source": [
    "features_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efectivamente solo se registran las columnas `calls`, `minutes`, `messages` y `mb_used` dentro de las variables features de cada conjunto de datos. Finalicemos la segmentación de datos, comprobando que los objetivos de los tres conjuntos presentan un propoción similar de registros para el plan Ultimate y Surf, para esto llamaremos al método value_counts con el argumento normalize=True para obtener valores relativos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.692427\n",
       "1    0.307573\n",
       "Name: is_ultra, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.706065\n",
       "1    0.293935\n",
       "Name: is_ultra, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_valid.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.684292\n",
       "1    0.315708\n",
       "Name: is_ultra, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se comprueba que la proporción de clientes Surf y Ultimate es similar en los tres conjuntos de datos, pudiendo encontrar alrededor del 70% de clientes Surf y 30% de clientes Ultimate tanto en el conjunto para el entrenamiento, validación y prueba. \n",
    "\n",
    "### Conclusiones\n",
    "\n",
    "1. Se dividió nuestro dataset fuente en tres conjuntos de datos necesarios para desarrollar un modelo de machine learning, el primer conjunto de datos para el entrenamiento `df_train` contiene el 60% de datos, el conjunto de validación `df_valid` contiene el 20% de datos y el conjunto de prueba `df_test` con el 20% de datos. \n",
    "2. Posteriormente se establecieron las características y objetivo de cada conjunto de datos, siendo las columnas `calls`, `messages`, `mb_used` y `minutes` las variables características y la columna `is_ultra` nuestro objetivo, ya que es el valor que nuestro modelo predicirá. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigación de modelos predictivos\n",
    "\n",
    "Una vez separado el conjunto de datos y establecidas las características y objetivo del conjunto de datos para el entrenamiento, validación y prueba, procederemos a investigar la calidad de diferentes modelos y escogeremos aquel que presente la mayor Exactitud (relación entre el número de respuestas correctas y el número total de preguntas). \n",
    "\n",
    "Recordemos que estamos trabajando con un objetivo categórico(Ultimate-1, Surf-0), por lo que vamos a trabajar con tres algoritmos de aprendizaje supervisado para generar diferentes modelos: árbol de decisión, bosque aleatorio y regresión logística. \n",
    "\n",
    "### Árbol de decisión\n",
    "\n",
    "El primer algoritmo de aprendizaje supervisado que utilizaremos es un árbol de decisión, este divide los datos en dos o más conjuntos homogéneos y utiliza reglas if-then o condiciones para separar los datos según las dos categorías que se busca predecir. Para trabajar con un árbol de decisión clasificatorio vamos a llamar a la función DecissionTreeClassifier del módulo tree en la librería Scikit-Learn, lo que ya hemos realizado en la sección de inicialización. \n",
    "\n",
    "Guardaremos a nuestro modelo en la variable `tree_model`, dentro de la cual llamaremos a la función DecissionTreeClassifier y estableceremos el hiperparamétro random_state=12345 para poder duplicar modelos existosos utilizando el mismo conjunto de números pseudoaleatorios. Para establecer la profundidad máxima o el número máximo de condiciones más apropiada para nuestro modelo, construiremos un bucle for que iterará por diferentes profundidades dentro del rango de 1 a 10. \n",
    "\n",
    "Posteriormente, vamos a entrenar nuestro modelo para esto pasaremos las características y el objetivo de nuestro conjunto de entrenamiento como argumento de la función fit. Luego crearemos la variable `predictions_valid` que predecirá los valores de clientes Surf o Ultimate en base a nuestro dataset de validación. A continuación, vamos a calcular la exactitud de cada modelo a diferentes profundidaes máximas, para esto utilizaremos la función `accuracy_score` que comparará los valores reales de planes en `target_valid` con los valores predichos `predictions_valid`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth= 1 :0.7542768273716952\n",
      "max_depth= 2 :0.7822706065318819\n",
      "max_depth= 3 :0.7853810264385692\n",
      "max_depth= 4 :0.7791601866251944\n",
      "max_depth= 5 :0.7791601866251944\n",
      "max_depth= 6 :0.7838258164852255\n",
      "max_depth= 7 :0.7822706065318819\n",
      "max_depth= 8 :0.7791601866251944\n",
      "max_depth= 9 :0.7822706065318819\n",
      "max_depth= 10 :0.7744945567651633\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1,11):\n",
    "    \n",
    "    tree_model = DecisionTreeClassifier(random_state=12345, max_depth=depth)\n",
    "    \n",
    "    tree_model.fit(features_train, target_train)\n",
    "    \n",
    "    predictions_valid = tree_model.predict(features_valid)\n",
    "       \n",
    "    print('max_depth=', depth, ':', end='')\n",
    "    print(accuracy_score(target_valid, predictions_valid))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al analizar los resultados de exactitud de nuestro modelo entrenado en el conjunto de validación, se puede concluir que la exactitud más alta registrada de 0.7853 corresponde al modelo de Árbol de Decisición clasificatorio con una profundidad máxima de 3, este sería nuestro modelo más exitoso ya que se encuentra por encima del umbral de exactitud esperado de 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bosque Aleatorio\n",
    "\n",
    "Nuestro segundo modelo lo vamos a construir a partir del algoritmo de aprendizaje conocido como Bosque Aleatorio. Estos se basan en árboles de decisión, pero no entrena un sólo árbol sino un bosque o una gran cantidad de árboles independientes y toman decisiones mediante el voto, es decir suman los votos de diferentes formaciones aleatorias de los árboles de decisión para determinar la clase final a la que pertenece un cliente. \n",
    "\n",
    "Para determinar el modelo de Bosque Aleatorio con mayor exactitud vamos a llamar a la función RandomForestClassifier del módulo ensemble de la librería Scikit-Learn, y guardaremos nuestro modelo en la variable `forest_model`. Dentro de la función pasaremos el hiperpárametro random_state=12345 para poder replicar nuestro modelo utilizando los mismos números pseudoaleatorios. En el caso de los hiperparámetros n-estimators(número de árboles en el bosque) y max_depth(profundidad máxima) vamos a generar un doble bucle for que iterará por un rango de profundidades de 1 a 10 y un rango de árboles de 10 a 50, en intervalos de 10, estableciendo así los valores ideales para un modelo de mayor exactitud. \n",
    "\n",
    "Entrenaremos nuestro modelo `forest_model` con nuestro conjunto de datos para el entrenamiento `features_train` y `target_train`, y posteriormente evaluaremos la calidad de nuestro modelo aplicando la función score a nuestro conjunto de validación `features_valid` y `target_valid`. Para poder determinar el número de árboles y profundidad máxima que generó el modelo con mayor exactitud vamos a establecer tres contadores `best_score`, `best_est` y `best_depth` que si registran el valor de exactitud más alto, guardarán los valores de max_depth y n_estimators que generaron dicha exactitud en los contadores previamente mencionados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del mejor modelo en el conjunto de validación (n_estimators = 40, max_depth = 8): 0.8087091757387247\n"
     ]
    }
   ],
   "source": [
    "best_score = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "\n",
    "for est in range(10,51,10):\n",
    "    \n",
    "    for depth in range(1,11):\n",
    "        \n",
    "        forest_model= RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        \n",
    "        forest_model.fit(features_train, target_train)\n",
    "        \n",
    "        score = forest_model.score(features_valid, target_valid)\n",
    "        \n",
    "        if score > best_score:\n",
    "            \n",
    "            best_score = score\n",
    "            best_est = est\n",
    "            best_depth = depth\n",
    "\n",
    "print(\"Exactitud del mejor modelo en el conjunto de validación (n_estimators = {}, max_depth = {}): {}\".format(best_est, best_depth, best_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor modelo de Bosque Aleatorio presentó una exactitud de 0.8087 en el conjunto de validación, con un número de árboles de decisión de 40 y una profundidad máxima de 8. Este modelo presenta una exactitud más alta que el modelo de Árbol de decisión que registró una exactitud 0.7853, sin embargo hay que considerar que el modelo es mucho más lento en su ejecución ya que mientras más árboles formen parte del modelo más lento trabajará el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Logística\n",
    "\n",
    "El último algoritmo de aprendizaje que utilizaremos para entrenar a nuestro modelo será el de Regresión Logística. Este algoritmo coloca nuestros datos en forma de una curva sigmoide y establece la probabilidad de que un determinado valor de llamadas, mensajes o datos corresponda con el plan Surf o Ultimate. El modelo calcula la proximidad de clase para cada observación en los datos de entrenamiento y les asigna leyendas, si la probabilidad es más cercana a cero se clasificará como Surf-0 y si la probabilidad es más cercana a 1 entonces se clasificará como Ultimate-1.\n",
    "\n",
    "Llamaremos a nuestro modelo `regression_model` y llamaremos a la función LogisticRegressión del módulo linear_model de la librería Scikit-learn, a esta función pasaremos los hiperparámetros para el posterior entrenamiento del modelo. Estableceremos los hiperparámetros random_state=12345 que volverá estática la pseudoaleatoriedad y solver=liblinear que se utiliza para el ajuste de curva del algoritmo en datasets pequeños. \n",
    "\n",
    "A continuación entrenaremos el modelo de regresión con el conjunto de entrenamiento `features_train` y `target_train` y evaluaremos la calidad del modelo en nuestro conjunto de validación para evitar el sobreajuste, para esto llamaremos a la función score y pasaremos como argumentos `features_valid` y `target_valid` para obtener la exactitud de nuestro modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo de Regresión Logística en el conjunto de validación: 0.7091757387247278\n"
     ]
    }
   ],
   "source": [
    "regression_model = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "\n",
    "regression_model.fit(features_train, target_train)\n",
    "\n",
    "score = regression_model.score(features_valid, target_valid)\n",
    "\n",
    "print(\"Exactitud del modelo de Regresión Logística en el conjunto de validación:\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el modelo de regresión logística se obtuvo una exactitud de 0.7091, la cual se encuentra por debajo de nuestro umbral de exactitud de 0.75, por lo que no se considerará este modelo para su aplicación en el conjunto de prueba que fue separado previamente. La exactitud de este modelo se encuentra por debajo de los modelos de árbol de decisión y bosque aleatorio, los cuales registraron valores por encima del umbral establecido en este proyecto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calidad del modelo\n",
    "\n",
    "Al investigar diferentes modelos predictivos se pudo establecer que los modelos que mejor predicen a qué plan de telefonía debería pertenecer un cliente son el modelo de Árbol de decisión y el modelo de Bosque Aleatorio que registraron una exactitud de 0.78 y 0.80 respectivamente. En el caso del modelo de Regresión Logística se registró una exactitud de 0.70, que se encuentra por debajo del umbral de 0.75 por lo que solo vamos a analizar la calidad de los dos primeros modelos en nuestro conjunto de prueba. \n",
    "\n",
    "En el caso del modelo de árbol de decisión se registró la exactitud más alta para un profundidad máxima de 3, así que aplicaremos estos valores de hiperparámetro a nuestro modelo, luego entrenaremos a nuestro modelo con el conjunto de datos de entrenamiento y estableceremos la exactitud del modelo en nuestro conjunto de prueba a través de score que tomará como argumentos `features_test` y `target_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo de Árbol de Decisión en el conjunto de prueba 0.7791601866251944\n"
     ]
    }
   ],
   "source": [
    "tree_model = DecisionTreeClassifier(random_state=12345, max_depth=3)\n",
    "\n",
    "tree_model.fit(features_train, target_train)\n",
    "\n",
    "print('Exactitud del modelo de Árbol de Decisión en el conjunto de prueba', tree_model.score(features_test, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el modelo de bosque aleatorio se registró la exactitud más alta con una profundidad máxima de 8 y un número de árboles de 40, entrenaremos nuestro modelo en base a estos hiperparámetros con el conjunto de datos de entrenamiento y obtendremos la exactitud del modelo en nuestro conjunto de datos de prueba, por lo que utilizaremos score tomando como argumentos a nuestro dataset de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del modelo de Bosque Aleatorio en el conjunto de prueba 0.7962674961119751\n"
     ]
    }
   ],
   "source": [
    "forest_model = RandomForestClassifier(random_state=12345, n_estimators=40, max_depth=8)\n",
    "\n",
    "forest_model.fit(features_train, target_train)\n",
    "\n",
    "print('Exactitud del modelo de Bosque Aleatorio en el conjunto de prueba', forest_model.score(features_test, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al probar nuestros dos modelos en el conjunto de prueba se registra una exactitud de 0.77 para el modelo de Árbol de Decisión y 0.79 para el modelo de Bosque Aleatorio. Considerando que la exactitud es un criterio clave para las empresas, ya que una exactitud alta va a categorizar correctamente a los usuarios de acuerdo al plan ideal de acuerdo a su consumo, generando más ingresos para Megaline, vamos a tomar al modelo de Bosque Aleatorio como nuestro modelo predictivo para este proyecto. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba de cordura\n",
    "\n",
    "Una vez establecido nuestro modelo predictivo de Bosque Aleatorio como el más propicio para predecir el plan ideal para clientes de Megaline, vamos a realizar un último análisis conocido como Prueba de Cordura que buscará problemas en las clasificicación del modelo comparando las predicciones en el conjunto de prueba con la aleatoriedad. Para esto vamos a generar una serie que será rellenada con valores aleatorios de 0 ó 1 y la guardaremos en la variable `predictions_random`. Para construir nuestro objeto Series vamos a utilizar la función pd.Series de Pandas y pasaremos como tamaño del objetivo valores aleatorios de 0 ó 1 a través de la función random.choice de numpy, estableceremos el tamaño de nuestro array de valores igual al tamaño de `target_test`. A su vez, estableceremos como índice del objeto Series los índices registrados en `target_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    325\n",
       "1    318\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Establecemos el valor que se establecerá como semilla para el generador de números pseudoaleatorios\n",
    "np.random.seed(54321)\n",
    "\n",
    "#Construimos nuestro objeto Series de valores aleatorios 0 ó 1\n",
    "predictions_random =  pd.Series(np.random.choice([0, 1], size=len(target_test)), index=target_test.index)\n",
    "\n",
    "#Comprobamos los valores únicos del objeto Series llamando a value_counts\n",
    "predictions_random.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se comprueba que nuestro objeto series está correctamente conformado por únicamente valores 0 ó 1, ahora vamos a realizar nuestra prueba de cordura para esto estableceremos la exactitud comparando los valores objetivo de nuestro conjunto de prueba con nuestras predicciones aleatorias `predictions_random`. Llamaremos a la función accuracy_score del módulo metrics de la librería Scikit-Learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud aleatoriedad: 0.49455676516329705\n",
      "Exactitud modelo predictivo: 0.7962674961119751\n"
     ]
    }
   ],
   "source": [
    "print('Exactitud aleatoriedad:', accuracy_score(target_test, predictions_random))\n",
    "print('Exactitud modelo predictivo:', forest_model.score(features_test, target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La exactitud de la aleatoriedad es de 0.48, menor a la exactitud de nuestro modelo de Bosque Aleatorio de 0.79, por lo que nuestro modelo ha pasado la prueba de cordura y presenta una exactitud mayor a la aleatoriedad, pudiendo predecir valores mejor que la posibilidad del azar. \n",
    "\n",
    "## Conclusiones\n",
    "\n",
    "1. Para la construcción de nuestro modelo, se segmentó nuestro dataset fuente en tres conjuntos de datos: conjunto de datos para el entrenamiento (60%), conjunto de datos para la validación (20%) y conjunto de datos prueba (20%). Esto se realizó para evitar el sobreajuste del modelo y para la correcta verificación de la calidad del modelo. \n",
    "\n",
    "2. Se probaron tres modelos de aprendizaje supervisado: árbol de decisión, bosque aleatorio y regresión logística. Se escogieron estos modelos ya que sirven para predecir tareas de tipo clasificatorio. \n",
    "\n",
    "3. El modelo de regresión logística registró una exactitud de 0.70 por debajo del umbral de este proyecto, por lo que fue descartado para el análisis de calidad del modelo. Por otro lado, el modelo de árbol de decisión presentó una exactitud de 0.77 en el conjunto de prueba y 0.78 en el conjunto de validación, por encima del umbral de 0.75 pero inferior a nuestro modelo de bosque aleatorio. \n",
    "\n",
    "4. Se concluye que el mejor modelo predictivo que permitirá escoger el plan de telefonía correcto para clientes con planes heredados de la telefonía Megaline es el modelo de Bosque Aleatorio. Este modelo presentó la exactitud más alta de 0.80 para el conjunto de validación y 0.79 para el conjunto de prueba, con hiperparámetros de n_estimators=40 y max_depth=8. A su vez, al comparar la exactitud del modelo con la aleatoriedad, este valor se mantuvo por encima del valor de exactitud del azar de 0.49, por lo que nuestro modelo es mejor categorizando a los clientes de Megaline que el azar. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de Contenidos",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "286.075px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
